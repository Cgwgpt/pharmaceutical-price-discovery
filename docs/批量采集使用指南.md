# 批量采集使用指南

## 功能概述

批量采集功能可以一次性采集搜索结果中的所有药品及其供应商价格。

### 使用场景

- ✅ 想要获取某个品类的所有药品数据
- ✅ 比如搜索"天麻蜜环菌片"，获取所有品牌/规格的数据
- ✅ 建立完整的药品价格数据库

### 与单个药品采集的区别

| 功能 | 单个药品采集 | 批量采集 |
|------|------------|---------|
| 采集对象 | 1个具体药品 | 多个不同药品 |
| 采集内容 | 该药品的所有供应商价格 | 每个药品的所有供应商价格 |
| 耗时 | 10-30秒 | (药品数 × 15秒) |
| 适用场景 | 查询特定药品价格 | 建立品类数据库 |

## 使用方法

### 1. Web界面使用

1. 访问采集管理页面：http://localhost:5001/crawl
2. 找到"📦 批量采集"卡片
3. 输入搜索关键词（如：天麻蜜环菌片）
4. 设置参数：
   - **最多采集药品数**：建议10-20个（避免时间过长）
   - **每个药品最多采集供应商数**：建议50个
5. 点击"📦 开始批量采集"
6. 等待采集完成（查看日志区域的实时进度）

### 2. API调用

```bash
curl -X POST "http://localhost:5001/api/crawl/batch-search" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "天麻蜜环菌片",
    "max_drugs": 10,
    "max_providers_per_drug": 50
  }'
```

### 3. Python代码调用

```python
from app.services.crawl_service import CrawlService

service = CrawlService()

result = service.crawl_all_search_results(
    keyword='天麻蜜环菌片',
    max_drugs=10,
    max_providers_per_drug=50,
    save_to_db=True
)

print(f"采集了 {result['total_drugs']} 个药品")
print(f"找到 {result['total_providers']} 个供应商")
print(f"保存了 {result['total_saved']} 条记录")
```

## 工作原理

```
1. 搜索关键词
   ↓
2. 获取所有匹配的药品列表
   ↓
3. 对每个药品：
   - 采集该药品的所有供应商价格
   - 保存到数据库
   ↓
4. 返回汇总结果
```

## 参数说明

### keyword（必填）
- 搜索关键词
- 例如："天麻蜜环菌片"、"阿莫西林"、"布洛芬"

### max_drugs（可选，默认10）
- 最多采集多少个药品
- 建议值：10-20
- 最大值：50（系统限制）
- 说明：药品数越多，耗时越长

### max_providers_per_drug（可选，默认50）
- 每个药品最多采集多少个供应商
- 建议值：50
- 最大值：200（系统限制）
- 说明：供应商数越多，数据越完整，但耗时也越长

## 返回结果

```json
{
  "code": 0,
  "data": {
    "keyword": "天麻蜜环菌片",
    "success": true,
    "total_drugs": 10,
    "total_providers": 520,
    "total_saved": 450,
    "drugs": [
      {
        "name": "5瓶起购 福建汇天 天麻蜜环菌片0.25g*100片",
        "drug_id": 12345,
        "providers_count": 59,
        "saved_count": 59,
        "success": true
      },
      {
        "name": "三明天泰 天麻蜜环菌片0.25g*100片",
        "drug_id": 12346,
        "providers_count": 45,
        "saved_count": 45,
        "success": true
      }
      // ... 更多药品
    ]
  },
  "message": "批量采集完成：10个药品，520个供应商"
}
```

## 性能和时间

### 预计耗时

| 药品数 | 预计耗时 | 说明 |
|-------|---------|------|
| 5个 | 1-2分钟 | 快速测试 |
| 10个 | 2-3分钟 | 推荐 |
| 20个 | 5-6分钟 | 较完整 |
| 50个 | 12-15分钟 | 最大值 |

### 性能优化建议

1. **首次采集**：使用较小的 max_drugs（如5-10）测试
2. **日常使用**：10-20个药品即可
3. **完整采集**：可以分批次采集，避免一次性采集过多

## 实际案例

### 案例1：采集天麻蜜环菌片所有品牌

```bash
# 搜索"天麻蜜环菌片"，采集前10个药品
curl -X POST "http://localhost:5001/api/crawl/batch-search" \
  -H "Content-Type: application/json" \
  -d '{
    "keyword": "天麻蜜环菌片",
    "max_drugs": 10
  }'
```

**结果**：
- 采集了10个不同品牌/规格的天麻蜜环菌片
- 找到520个供应商价格
- 保存了450条新记录（70条已存在）
- 耗时：约2.5分钟

### 案例2：采集感冒药品类

```python
from app.services.crawl_service import CrawlService

service = CrawlService()

# 采集感冒药
result = service.crawl_all_search_results(
    keyword='感冒',
    max_drugs=20,
    max_providers_per_drug=50,
    save_to_db=True
)

print(f"采集了 {result['total_drugs']} 种感冒药")
print(f"共 {result['total_providers']} 个供应商")
```

## 注意事项

### 1. 时间控制
- ⚠️ 批量采集耗时较长，建议在非高峰时段运行
- ⚠️ 不要设置过大的 max_drugs，避免超时

### 2. 数据去重
- ✅ 系统会自动检查重复记录
- ✅ 已存在的价格不会重复保存
- ✅ 只保存新增的价格记录

### 3. 错误处理
- ✅ 单个药品采集失败不影响其他药品
- ✅ 会在结果中标注失败的药品
- ✅ 可以查看日志了解失败原因

### 4. Token有效性
- ⚠️ 确保Token有效
- ⚠️ 批量采集前先检查Token状态
- ⚠️ Token过期会导致所有采集失败

## 常见问题

### Q1: 为什么采集的药品数少于设置的max_drugs？

**原因**：
- 搜索结果本身就少于max_drugs
- 部分药品采集失败

**解决**：
- 检查搜索关键词是否正确
- 查看日志了解失败原因

### Q2: 为什么saved_count少于providers_count？

**原因**：
- 部分价格记录已经存在于数据库中
- 系统自动去重，不重复保存

**说明**：
- 这是正常现象
- saved_count 是新增的记录数
- 数据库中的总记录数 = 原有 + saved_count

### Q3: 批量采集可以中断吗？

**答案**：
- 目前不支持中断
- 建议设置较小的max_drugs进行测试
- 如果需要中断，可以刷新页面（已采集的数据会保存）

### Q4: 如何查看采集的数据？

**方法**：
1. 访问搜索页面：http://localhost:5001/search
2. 搜索药品名称
3. 查看价格列表

或者使用SQL查询：
```sql
SELECT d.name, COUNT(pr.id) as 供应商数
FROM drugs d
LEFT JOIN price_records pr ON d.id = pr.drug_id
WHERE d.name LIKE '%天麻蜜环菌片%'
GROUP BY d.id
```

## 最佳实践

### 1. 分批采集
```python
# 不推荐：一次采集50个
result = service.crawl_all_search_results(keyword='感冒', max_drugs=50)

# 推荐：分批采集
keywords = ['感冒灵', '板蓝根', '连花清瘟']
for kw in keywords:
    result = service.crawl_all_search_results(keyword=kw, max_drugs=10)
```

### 2. 定时采集
```python
# 使用定时任务每天采集
from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler()

def daily_batch_crawl():
    service = CrawlService()
    keywords = ['天麻蜜环菌片', '阿莫西林', '布洛芬']
    for kw in keywords:
        service.crawl_all_search_results(keyword=kw, max_drugs=10)

scheduler.add_job(daily_batch_crawl, 'cron', hour=2)  # 每天凌晨2点
scheduler.start()
```

### 3. 监控采集结果
```python
result = service.crawl_all_search_results(keyword='天麻蜜环菌片', max_drugs=10)

# 检查成功率
success_count = sum(1 for d in result['drugs'] if d.get('success'))
success_rate = success_count / result['total_drugs'] * 100

print(f"成功率: {success_rate:.1f}%")

# 检查失败的药品
failed_drugs = [d for d in result['drugs'] if not d.get('success')]
if failed_drugs:
    print("失败的药品：")
    for drug in failed_drugs:
        print(f"  - {drug['name']}: {drug.get('error')}")
```

## 技术细节

### 采集策略

1. **优先使用API**：快速获取搜索结果
2. **Playwright备用**：API失败时使用Playwright搜索
3. **逐个采集**：对每个药品使用完整模式采集
4. **自动保存**：采集完成后自动保存到数据库

### 数据流程

```
用户输入关键词
    ↓
API搜索 → 获取药品列表
    ↓
遍历每个药品
    ↓
完整模式采集 → 获取供应商价格
    ↓
保存到数据库 → 去重检查
    ↓
返回汇总结果
```

## 总结

批量采集功能适合：
- ✅ 建立完整的药品价格数据库
- ✅ 采集某个品类的所有药品
- ✅ 定期更新多个药品的价格

使用建议：
- 💡 首次使用时设置较小的max_drugs测试
- 💡 根据实际需求调整参数
- 💡 定期运行以保持数据更新
- 💡 监控采集结果和成功率

---

*医药价格发现系统 © 2025*
