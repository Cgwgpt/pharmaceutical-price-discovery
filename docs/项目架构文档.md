# 医药价格发现系统 - 项目架构文档

## 1. 系统概述

### 1.1 项目简介

医药价格发现系统是一个基于Flask的Web应用，用于采集、分析和比较医药产品价格。系统支持从药师帮平台采集价格数据，提供智能分类、异常检测、价格监控和采购建议等功能。

### 1.2 核心特性

- **智能采集**: API快速模式 + Playwright完整模式
- **商品分类**: 自动识别药品、化妆品、医疗器械、保健品 (准确率100%)
- **异常检测**: 自动标注异常价格，使用IQR统计方法
- **批量管理**: 支持监控列表和批量采集任务
- **价格监控**: 实时监控价格变化，自动预警
- **采购建议**: 基于价格分析提供最优采购方案

### 1.3 技术选型

| 技术 | 版本 | 用途 |
|------|------|------|
| Python | 3.8+ | 开发语言 |
| Flask | 2.3+ | Web框架 |
| SQLAlchemy | 2.0+ | ORM |
| SQLite | 3.x | 数据库 |
| Scrapy | 2.11+ | 爬虫框架 |
| Playwright | 1.x | 浏览器自动化 |
| APScheduler | 3.10+ | 任务调度 |
| Bootstrap | 5.x | 前端UI |

## 2. 系统架构

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                      用户界面层                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌─────────┐ │
│  │ 药品列表 │  │ 价格监控 │  │ 采集管理 │  │ 采购建议│ │
│  └──────────┘  └──────────┘  └──────────┘  └─────────┘ │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                      应用层 (Flask)                      │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌─────────┐ │
│  │  Routes  │  │   API    │  │Scheduler │  │ Models  │ │
│  └──────────┘  └──────────┘  └──────────┘  └─────────┘ │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                      业务逻辑层                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌─────────┐ │
│  │采集服务  │  │价格服务  │  │监控服务  │  │比价服务│ │
│  ├──────────┤  ├──────────┤  ├──────────┤  ├─────────┤ │
│  │预警服务  │  │推荐服务  │  │报表服务  │  │标准化   │ │
│  └──────────┘  └──────────┘  └──────────┘  └─────────┘ │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                      数据采集层                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌─────────┐ │
│  │API爬虫   │  │Playwright│  │Token管理 │  │自动登录│ │
│  └──────────┘  └──────────┘  └──────────┘  └─────────┘ │
└─────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────┐
│                      数据存储层                          │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐              │
│  │  SQLite  │  │  Cache   │  │  Files   │              │
│  └──────────┘  └──────────┘  └──────────┘              │
└─────────────────────────────────────────────────────────┘
```

### 2.2 模块划分

#### 2.2.1 应用核心 (app/)

**职责**: Flask应用初始化、路由、模型定义

**主要文件**:
- `__init__.py`: 应用工厂模式
- `models.py`: 数据模型定义
- `routes.py`: 页面路由
- `api.py`: API接口
- `scheduler.py`: 定时任务

#### 2.2.2 业务逻辑层 (app/services/)

**职责**: 核心业务逻辑实现

**服务列表**:

| 服务 | 文件 | 职责 |
|------|------|------|
| 采集服务 | crawl_service.py | 数据采集、批量管理 |
| 价格服务 | price_service.py | 价格查询、统计 |
| 监控服务 | monitor_service.py | 价格监控、预警 |
| 比价服务 | compare_service.py | 价格比较、分析 |
| 预警服务 | alert_service.py | 预警规则、通知 |
| 推荐服务 | recommendation_service.py | 采购建议 |
| 报表服务 | report_service.py | 数据报表 |
| 标准化服务 | normalize_service.py | 数据标准化 |

#### 2.2.3 爬虫模块 (scraper/)

**职责**: 数据采集实现

**主要组件**:
- `spiders/`: 爬虫定义
- `utils/`: 工具模块
- `middlewares.py`: 中间件
- `pipelines.py`: 数据管道

#### 2.2.4 前端模板 (app/templates/)

**职责**: 用户界面

**页面列表**:
- `index.html`: 首页
- `drugs_list.html`: 药品列表
- `drug_detail.html`: 药品详情
- `crawl.html`: 采集管理
- `monitor.html`: 价格监控
- `procurement.html`: 采购建议

## 3. 数据模型

### 3.1 核心模型

#### Drug (药品)

```python
class Drug(Base):
    id: int                    # 主键
    name: str                  # 药品名称
    standard_name: str         # 标准名称
    specification: str         # 规格
    manufacturer: str          # 厂家
    category: str             # 类别 (drug/cosmetic/medical_device/health_product)
    approval_number: str      # 批准文号
    created_at: datetime      # 创建时间
    updated_at: datetime      # 更新时间
```

#### PriceRecord (价格记录)

```python
class PriceRecord(Base):
    id: int                    # 主键
    drug_id: int              # 药品ID (外键)
    price: Decimal            # 价格
    source_name: str          # 来源名称
    source_url: str           # 来源URL
    crawled_at: datetime      # 采集时间
    is_outlier: int           # 异常标注 (0=正常, 1=异常高, -1=异常低, 2=占位)
    outlier_reason: str       # 异常原因
```

#### CrawlTask (采集任务)

```python
class CrawlTask(Base):
    id: int                    # 主键
    task_name: str            # 任务名称
    keywords: str             # 关键词列表 (JSON)
    status: str               # 状态 (pending/running/completed/failed)
    total_keywords: int       # 总关键词数
    completed_keywords: int   # 已完成数
    total_items: int          # 采集数据量
    started_at: datetime      # 开始时间
    completed_at: datetime    # 完成时间
```

#### DrugWatchList (监控列表)

```python
class DrugWatchList(Base):
    id: int                    # 主键
    keyword: str              # 关键词
    category: str             # 分类
    priority: int             # 优先级 (0=普通, 1=重要, 2=紧急)
    is_active: bool           # 是否激活
    last_crawled_at: datetime # 最后采集时间
    crawl_count: int          # 采集次数
```

### 3.2 数据关系

```
Drug (1) ←→ (N) PriceRecord
Drug (1) ←→ (N) DrugAlias
Drug (1) ←→ (N) MonitorRule
```

## 4. 核心功能实现

### 4.1 智能采集

#### 4.1.1 采集模式

**快速模式 (API)**:
```python
def crawl_quick_mode(keyword, drug_id=None):
    # 1. 调用药师帮API
    # 2. 获取热销供应商价格 (1-10个)
    # 3. 保存到数据库
    # 速度: 1-3秒
```

**完整模式 (Playwright)**:
```python
def crawl_complete_mode(keyword, drug_id=None):
    # 1. 启动浏览器
    # 2. 访问详情页
    # 3. 拦截API请求
    # 4. 获取所有供应商价格 (50-100个)
    # 5. 保存到数据库
    # 速度: 10-30秒
```

**智能模式 (推荐)**:
```python
def crawl_with_smart_strategy(keyword, min_providers=5):
    # 1. 优先使用API采集
    # 2. 如果供应商数量 < min_providers
    # 3. 自动切换到Playwright补充
    # 4. 合并结果并去重
    # 速度: 3-15秒
```

#### 4.1.2 采集流程

```
开始
  ↓
获取Token
  ↓
选择采集模式
  ├─→ 快速模式 → API请求 → 解析数据
  ├─→ 完整模式 → Playwright → 拦截API
  └─→ 智能模式 → API → 判断 → Playwright (可选)
  ↓
数据清洗
  ↓
商品分类识别
  ↓
保存到数据库
  ↓
异常价格标注
  ↓
结束
```

### 4.2 商品分类

#### 4.2.1 识别算法

```python
def _detect_product_category(product_name, manufacturer=''):
    """
    优先级排序:
    1. 处方药/OTC标识 (置信度=1.0)
    2. 厂家信息 (置信度=0.95)
    3. 高置信度关键词 (置信度=0.9)
    4. 药品剂型 (置信度=0.85)
    5. 保健品关键词 (置信度=0.8)
    6. 维生素类判断 (置信度=0.6-0.75)
    7. 低置信度关键词 (置信度=0.7)
    8. 默认分类 (置信度=0.5)
    
    返回: {category, confidence, reason}
    """
```

#### 4.2.2 关键词库

**化妆品**:
- 高置信度: 珍珠霜、珍珠膏、面霜、乳液、精华液
- 厂家: 化妆品有限公司

**医疗器械**:
- 高置信度: 血糖仪、血压计、医用口罩、创可贴
- 厂家: 医疗器械有限公司

**药品**:
- 标识: (RX)、(OTC)
- 剂型: 片、胶囊、颗粒、口服液、注射液

**保健品**:
- 关键词: 益生菌软糖、蛋白粉、鱼油

### 4.3 异常检测

#### 4.3.1 检测算法

使用四分位距(IQR)方法:

```python
def _mark_price_outliers(session):
    for drug in drugs:
        prices = get_prices(drug.id)
        
        # 1. 标注占位价格
        if price in [9999, 99999, 999999]:
            mark_as_outlier(price, type=2, reason='占位价格')
        
        # 2. 计算IQR
        Q1 = percentile(prices, 25)
        Q3 = percentile(prices, 75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # 3. 标注离群值
        if price < lower_bound:
            mark_as_outlier(price, type=-1, reason='异常低价')
        elif price > upper_bound:
            mark_as_outlier(price, type=1, reason='异常高价')
```

#### 4.3.2 标注类型

| 类型 | is_outlier | 说明 |
|------|-----------|------|
| 正常 | 0 | 正常价格 |
| 异常高价 | 1 | 高于上界 |
| 异常低价 | -1 | 低于下界 |
| 占位价格 | 2 | 9999等 |

### 4.4 批量采集

#### 4.4.1 任务管理

```python
# 创建任务
task = create_crawl_task(
    keywords=['阿莫西林', '头孢克肟'],
    task_name='抗生素采集'
)

# 启动任务 (异步)
start_crawl_task(task.id, async_mode=True)

# 监控进度
progress = task.completed_keywords / task.total_keywords * 100

# 取消任务
cancel_crawl_task(task.id)
```

#### 4.4.2 监控列表

```python
# 添加到监控列表
add_to_watch_list(
    keyword='阿莫西林',
    category='抗生素',
    priority=1
)

# 定时采集
scheduler.add_job(
    func=crawl_watch_list,
    trigger='cron',
    hour=2  # 每天凌晨2点
)
```

## 5. API设计

### 5.1 RESTful API

#### 药品相关

```
GET    /api/drugs/search          # 搜索药品
GET    /api/drugs/{id}            # 获取药品详情
GET    /api/drugs/{id}/prices     # 获取价格列表
GET    /api/drugs/list            # 获取药品列表
```

#### 采集相关

```
POST   /api/crawl/quick           # 快速采集
POST   /api/crawl/complete        # 完整采集
POST   /api/crawl/smart           # 智能采集
GET    /api/crawl/tasks           # 获取任务列表
POST   /api/crawl/tasks           # 创建任务
GET    /api/crawl/tasks/{id}      # 获取任务详情
POST   /api/crawl/tasks/{id}/start # 启动任务
POST   /api/crawl/tasks/{id}/cancel # 取消任务
```

#### 监控相关

```
GET    /api/monitor/rules         # 获取监控规则
POST   /api/monitor/rules         # 创建监控规则
GET    /api/monitor/alerts        # 获取预警列表
```

### 5.2 请求示例

#### 搜索药品

```http
GET /api/drugs/search?keyword=阿莫西林&page=1&per_page=20

Response:
{
  "drugs": [
    {
      "id": 1,
      "name": "阿莫西林胶囊",
      "specification": "0.25g*24粒",
      "manufacturer": "XX制药",
      "category": "drug",
      "min_price": 5.5,
      "max_price": 12.8
    }
  ],
  "total": 15,
  "pages": 1
}
```

#### 快速采集

```http
POST /api/crawl/quick
Content-Type: application/json

{
  "keywords": ["阿莫西林", "头孢克肟"],
  "max_pages": 3
}

Response:
{
  "success": true,
  "total_items": 45,
  "results": [
    {
      "keyword": "阿莫西林",
      "items_count": 23,
      "success": true
    }
  ]
}
```

## 6. 性能优化

### 6.1 数据库优化

```python
# 索引优化
CREATE INDEX idx_drug_name ON drugs(name);
CREATE INDEX idx_price_drug_id ON price_records(drug_id);
CREATE INDEX idx_price_crawled_at ON price_records(crawled_at);

# 查询优化
# 使用子查询获取最新价格
SELECT * FROM (
    SELECT *, ROW_NUMBER() OVER (
        PARTITION BY drug_id 
        ORDER BY crawled_at DESC
    ) as rn
    FROM price_records
) WHERE rn = 1;
```

### 6.2 缓存策略

```python
# Redis缓存
cache.set(f'drug:{drug_id}', drug_data, timeout=3600)
cache.set(f'prices:{drug_id}', prices, timeout=1800)

# 本地缓存
@lru_cache(maxsize=1000)
def get_drug_by_id(drug_id):
    return session.query(Drug).get(drug_id)
```

### 6.3 并发控制

```python
# 限制并发数
semaphore = asyncio.Semaphore(3)

async def crawl_with_limit(keyword):
    async with semaphore:
        return await crawl(keyword)

# 请求间隔
await asyncio.sleep(CRAWL_DELAY)
```

## 7. 部署架构

### 7.1 开发环境

```
┌─────────────┐
│   开发机    │
│  Python 3.8 │
│   SQLite    │
│   Flask Dev │
└─────────────┘
```

### 7.2 生产环境

```
┌──────────────────────────────────────┐
│            Nginx (反向代理)           │
└──────────────────────────────────────┘
                  ↓
┌──────────────────────────────────────┐
│      Gunicorn (4 workers)            │
│         Flask App                     │
└──────────────────────────────────────┘
                  ↓
┌──────────────────────────────────────┐
│         PostgreSQL                    │
│         Redis (缓存)                  │
└──────────────────────────────────────┘
```

### 7.3 Docker部署

```dockerfile
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5001
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5001", "run:app"]
```

## 8. 安全考虑

### 8.1 数据安全

- Token加密存储
- 敏感信息脱敏
- SQL注入防护
- XSS防护

### 8.2 访问控制

- 用户认证
- 权限管理
- API限流
- CSRF保护

### 8.3 爬虫合规

- 遵守robots.txt
- 控制请求频率
- 使用合法Token
- 数据仅用于价格比较

## 9. 监控与日志

### 9.1 日志系统

```python
# 日志配置
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

# 日志记录
logger.info(f"采集 {keyword}: 成功")
logger.error(f"采集失败: {error}")
```

### 9.2 性能监控

- 响应时间监控
- 数据库查询性能
- 爬虫成功率
- 系统资源使用

## 10. 未来规划

### 10.1 短期 (1-3个月)

- [ ] 添加用户认证系统
- [ ] 支持更多数据源
- [ ] 移动端适配
- [ ] 数据导出功能

### 10.2 中期 (3-6个月)

- [ ] 机器学习价格预测
- [ ] 智能推荐算法优化
- [ ] 分布式爬虫
- [ ] 实时价格推送

### 10.3 长期 (6-12个月)

- [ ] 微服务架构改造
- [ ] 大数据分析平台
- [ ] 移动APP开发
- [ ] 开放API平台

## 附录

### A. 代码统计

**项目规模**:
- Python文件: 61个, 13,622行 (代码10,306行, 注释806行, 空行2,510行)
- HTML文件: 11个, 2,947行
- Markdown文件: 30个, 8,848行
- 总计: 102个文件, 25,417行

**模块分布**:

| 模块 | 文件数 | 总行数 | 代码行数 | 注释行 | 空行 |
|------|--------|--------|---------|--------|------|
| app | 14 | 7,064 | 5,399 | 345 | 1,320 |
| scraper | 15 | 3,492 | 2,582 | 247 | 663 |
| tests | 3 | 325 | 248 | 28 | 49 |
| root | 29 | 2,741 | 2,077 | 186 | 478 |
| **总计** | **61** | **13,622** | **10,306** | **806** | **2,510** |

### B. 依赖列表

见 `requirements.txt`

### C. 参考文档

- [Flask文档](https://flask.palletsprojects.com/)
- [SQLAlchemy文档](https://www.sqlalchemy.org/)
- [Scrapy文档](https://scrapy.org/)
- [Playwright文档](https://playwright.dev/)
